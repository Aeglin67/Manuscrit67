\chapter{Segmentation des tissus cérébraux en IRM : État de l'art}
\label{chap:art}
\minitoc

État de l'art en segmentation des tissus cérébraux avec une dernière partie consacrée à l'étude de la maturation cérébrale (jeunes enfants, nouveaux nés et f\oe tus).

%------------------------------------------------------------------------Vue d'ensemble----------------------------------------------------------------------------------------

\section{Vue d'ensemble}
\label{sec:overview}

\subsection{Modèles déformables}
\label{subsec:snake}

\cite{McInerney:TMI:1999} : Snake avec formulation particulière de la surface permettant la segmentation de structures complexes.

\cite{Baillard:MIA:2001} : deux étapes, recalage d'un modèle puis évolution des level-sets multigrille et multi-résolution.

\cite{Han:TPAMI:2003} : Levels sets introduisant une contrainte topologique.

\cite{Yang:TMI:2004} : Évolution de levels sets via estimation du MAP et contraintes de voisinages $\rightarrow$ structures internes.

\cite{Duncan:NeuroImage:2004} : deux level-sets (LCR/MG et MG/MB) évoluent en parallèle dans la cadre d'une estimation du MAP et de contraintes de voisinage $\rightarrow$ cortex.

\cite{Colliot:PR:2006} : Modèle déformable intégrant des contraintes de localisation (angle et distance) sous forme floue par rapport à une structure de référence $\rightarrow$ segmentation des noyaux gris autour des ventricules.

\cite{Ciofolo:MIA:2009} : Level sets concurrents évoluant selon un système de décision flou prenant en compte un \emph{a priori} donné par un atlas anatomique, l'intensité des voxels et la position du contour dans l'image.

\subsection{Croissance de régions}
\label{subsec:regionGrowing}

\subsection{Approches topologiques}
\label{subsec:topologie}

\cite{Mangin:JMIV:1995} : Représentation du cortex à partir de la squelettisation de l'ensemble LCR/Cortex.

\cite{MacDonald:NeuroImage:2000} : Segmentation du cortex par level-sets concurrents avec les contraintes suivantes : les deux surfaces ne peuvent pas se croiser + épaisseur max du cortex.

\cite{Han:TMI:2002} : Correction de la topologie par un graphe et un approche multi-échelle (représentée par une série d'ouvertures morphologiques avec une élément structurant de taille croissante).

\cite{Dokladal:PR:2003} : Segmentation des structures cérébrales une à une par une série d'opérations de morpho-maths supervisées par des contraintes topologiques.

\cite{Bazin:TMI:2007} : Utilisation d'un atlas anatomique topologique et de l'algorithme FCM avec érosions et dilatations successives des différents labels. Contraintes topologiques par point simple.

\cite{Bazin:MIA:2008} : Ajout d'un atlas statistique et de contraintes homéomorphiques digitales par rapport à \cite{Bazin:TMI:2007}

\cite{Pham:SPM:2010} : État de l'art sur l'utilisation de la topologie pour la segmentation des tissus.

\subsection{Utilisation d'atlas}
\label{subsec:atlas}

\cite{Ashburner:NeuroImage:2005} : Méthode reposant quasi complètement sur le recalage d'un atlas et introduisant un \emph{a priori} sur les tissus combinant l'\emph{a priori} de l'atlas pondéré par la quantité de tissus présent dans un petit volume $\rightarrow$ résistance au bruit.

\subsection{Classification}
\label{subsec:classif}

On précise que FCM est présenté à la section suivante.

\subsubsection{Méthodes non paramétriques}
\label{subsubsec:nonParam}

\cite{Warfield:MIA:2000} : Classification par kPPV supervisée par un ensemble de prototypes désignés par un expert et contrainte par un modèle anatomique.

\cite{Cocosco:MIA:2003} : Deux étapes : sélection automatique de l'ensemble d'apprentissage par élagage d'un arbre couvrant minimale d'un ensemble de voxels (première sélection à partir d'un atlas) + kPPV supervisé par l'ensemble d'apprentissage.

\cite{Jimenez-Alaniz:TMI:2006} : Estimation de la densité de probabilité par Mean-Shift et segmentation par a priori sur les tissus et carte de confiance des bords. Non-supervisée.

\cite{Mayer:TMI:2009} : Mean-Shift basé sur l'intensité et les coordonnées spatiales (inclue ainsi un \emph{a priori} spatial) puis réduction par fusion des différents modes obtenus puis $k$-means pondérés par le nombre de voxels de chaque cluster pour obtenir la segmentation finale. Non supervisée.

\cite{Richard:AIM:2004} : Approche multi-agents.


\subsubsection{Mixtures de gaussienne}
\label{subsubsec:gaussianMix}

Modélisation par mixtures de gaussienne, optimisation par l'algorithme EM~\cite{Dempster:JRSS:1977} et ajout des champs (\cite{Geman:PAMI:1984}) ou chaînes de Markov pour la régularisation.

\cite{VanLeemput1:TMI:1999, VanLeemput2:TMI:1999} : EM avec estimation du biais et régularisation par champs de Markov.

\cite{Zhang:TMI:2001} : EM avec régularisation par champs de Markov cachés.

\cite{Shattuck:NeuroImage:2001} : 3 classes pures + 3 classes volume partiels + \emph{a priori} markovien.

\cite{Kovacevic:NeuroImage:2002} : estime l'histogramme de l'espace cérébral par une mixture de 4 gaussienne au niveau global et locale (régions).

\cite{Bricq:MIA:2008} : EM avec utilisation des chaînes de Markov.

\cite{Scherrer:TMI:2009} : Segmentation conjointe des tissus et des structures cérébrales par un modèle de champs de Markov locaux distribués.

\subsubsection{$K$-Moyennes}
\label{subsubsec:kMeans}

Définition des K-Moyennes.
Utilisation en segmentation des tissus : \cite{Vemuri:IAACG:1995}.

%------------------------------------------------------------------------État de l'art FCM----------------------------------------------------------------------------------------

\section{Utilisation des $C$-Moyennes floues (FCM) en segmentation des tissus cérébraux}
\label{sec:fcm}

Par définition, l'algorithme des $C$-moyennes floues (FCM) donne une solution native au problème du volume partiel car il fournit des cartes de segmentation indiquant la proportion de chaque classe dans chaque élément de l'image.
Cependant, sa définition classique (voir la section~\ref{subsec:fcm:def}) ne permet pas d'apporter de réponse au problème du biais en intensité, ni à celui du bruit comme illustré par les figures~\ref{FIG:EX:FCM:PVE}, \ref{FIG:EX:FCM:NOISE} et \ref{FIG:EX:FCM:BIAS}.
Malgré ces handicaps, cet algorithme se révèle suffisamment souple pour y intégrer de multiples extensions permettant de prendre en compte les spécificités de l'imagerie anatomique et d'obtenir une segmentation fiable des tissus cérébraux.
La suite de cette section est une discussion des différentes options considérées ces dix dernières années pour améliorer l'algorithme FCM et permettre son utilisation en segmentation des tissus cérébraux.

\subsection{Définition de FCM}
\label{subsec:fcm:def}

\begin{figure*}[!htb]
\centering
\subfigure[]{\includegraphics[width=32mm]{eps/chapitre2/original.eps}}
\hspace{1mm}
\subfigure[]{\includegraphics[width=32mm]{eps/chapitre2/gm_classic.eps}}
\hspace{1mm}
\subfigure[]{\includegraphics[width=32mm]{eps/chapitre2/wm_classic.eps}}
\hspace{1mm}
\subfigure[]{\includegraphics[width=32mm]{eps/chapitre2/csf_classic.eps}}
\caption{\emph{
Segmentation par FCM illustrant l'effet de volume partiel.
(a) Une coupe d'IRM cérébrale.
(b--d) Segmentation de (a): (b) matière grise, (c) matière blanche, (d) LCR.
\label{FIG:EX:FCM:PVE}}}
%\end{figure}
\vspace{3mm}
%\begin{figure}[!htp]
\centering
\subfigure[]{\includegraphics[width=32mm]{eps/chapitre2/original_noise.eps}}
\hspace{1mm}
\subfigure[]{\includegraphics[width=32mm]{eps/chapitre2/gm_noise.eps}}
\hspace{1mm}
\subfigure[]{\includegraphics[width=32mm]{eps/chapitre2/wm_noise.eps}}
\hspace{1mm}
\subfigure[]{\includegraphics[width=32mm]{eps/chapitre2/csf_noise.eps}}
\caption{\emph{
Segmentation par FCM d'une image bruitée.
(a) Une coupe d'IRM cérébrale (similaire à celle de la Figure~\ref{FIG:EX:FCM:PVE}(a)) altérée par un bruit.
(b--d) Segmentation de (a): (b) matière grise, (c) matière blanche, (d) LCR.
\label{FIG:EX:FCM:NOISE}}}
%\end{figure}
\vspace{3mm}
%\begin{figure}[!htp]
\centering
\subfigure[]{\includegraphics[width=32mm]{eps/chapitre2/original_bias.eps}}
\hspace{1mm}
\subfigure[]{\includegraphics[width=32mm]{eps/chapitre2/gm_bias.eps}}
\hspace{1mm}
\subfigure[]{\includegraphics[width=32mm]{eps/chapitre2/wm_bias.eps}}
\hspace{1mm}
\subfigure[]{\includegraphics[width=32mm]{eps/chapitre2/csf_bias.eps}}
\caption{\emph{
Segmentation par FCM d'une image présentant un biais en intensité.
(a) Une coupe d'IRM cérébrale (similaire à celle de la Figure~\ref{FIG:EX:FCM:PVE}(a)) altérée par un biais.
(b--d) Segmentation de (a): (b) matière grise, (c) matière blanche, (d) LCR.
\label{FIG:EX:FCM:BIAS}}}
\end{figure*}

La première définition de l'algorithme FCM remonte à l'article de \cite{Zadeh:IC:1965} et s'appuie sur la notion d'ensembles flous.
Très vite, cet algorithme a trouvé des applications, notamment dans le cadre médicale, comme en témoignent les publications de : \cite{Adey:IJN:1972}, \cite{Bezdek:NCC:1976} et \cite{Kalmanson:AJC:1975}.
Il part du principe qu'une donnée n'a pas à être classée dans une classe en particulier, mais à plusieurs avec un certain degré d'appartenance.

L'algorithme FCM calcule une mesure de cette appartenance, via une fonction d'appartenance floue~\cite{Pham:IJPRAI:1996}, en chaque voxel de l'image et pour un nombre donné de classes.
Soit une image $I : \Omega \rightarrow \mathbf{Y}$, où $\Omega$ est le support de l'image et $\mathbf{Y}$ l'espace des intensités.
Il contient $N$ voxels, $\mathbf{x}_{j}$ et $\mathbf{y}_{j}$ représentent respectivement les coordonnées spatiales et l'intensité du voxel $j$.

L'algorithme FCM effectue une série d'itération entre l'évaluation de la fonction d'appartenance floue $u_{jk}$ et le calcul des centroïdes des classes $\mathbf{v}_k$.
La fonction d'appartenance est calculée en chaque voxel et pour chaque classe.
Elle est contrainte de manière que $0 \leq u_{jk} \leq 1$ et que $\sum_{k=1}^{C} u_{jk} = 1$, où $C$ est le nombre de classes.
Cette donnée est supposée connue.
Un fort degré d'appartenance (proche de $1$) signifie que l'intensité du voxel considéré est proche du centroïde de la classe, ce dernier étant considéré comme un prototype représentatif de l'intensité de la classe considérée.

Mathématiquement, l'algorithme FCM se déroule de la façon suivante : 
\begin{enumerate}
        \item Initialisation des centroïdes (peut-être faite par un algorithme $k$-means, où grâce à un atlas).
        \item Calcul de la fonction d'appartenance floue par $u_{jk} = \frac{D^{2}(\mathbf{y}_j, \mathbf{v}_k)}{\sum_{k=1}^{C} D^{2}(\mathbf{y}_j, \mathbf{v}_k)}$, où $D^{2}(\mathbf{y}_j, \mathbf{v}_k)$ représente une mesure de la similarité entre l'intensité au voxel $j$ et le centroïde de la classe $k$.
        \item Calcul des nouveaux centroïdes : $\mathbf{v}_k = \frac{\sum_{i \in \Omega}u_{jk}\mathbf{y}_j}{\sum_{i \in \Omega}u_{jk}}$.
        \item Si il y'a convergence, arrêt de l'algorithme, sinon retour au point 2.
\end{enumerate}

Ces itérations reviennent à effectuer un processus de minimisation de la fonction de coût suivante : 
\begin{equation}
J_{FCM} = \sum_{j \in \Omega} \sum_{k=1}^{C} u^{q}_{jk} D^{2}(\mathbf{y}_{j},\mathbf{v}_{k}) \label{eq:fcm},
\end{equation}
où $q$ est le degré de flou de la segmentation, habituellement fixé à $2$ dans la littérature.
La convergence est atteinte lorsqu'un minimum local de cette fonction est détectée.
De manière générale, le calcul de la similarité entre l'intensité des voxels et les centroïdes des classes est réalisé par la norme euclidienne, ce qui se traduit mathématiquement par : $D^{2}(\mathbf{y}_{j},\mathbf{v}_{k}) = \lVert \mathbf{y}_{j} - \mathbf{v}_{k} \rVert_{2}^{2}$.

L'hypothèse fondamentale faite lors de l'utilisation de l'algorithme FCM en segmentation anatomique est que chaque tissu peut-être représenté par une unique valeure $\mathbf{v}_k$, qui serait uniforme sur l'ensemble du domaine de l'image.
Les variations de cette \og vraie \fg{} valeur sont alors imputés au biais de l'image, au bruit et à l'effet de volume partiel (mélange de plusieurs tissus au sein d'un même voxel dont les proportions déterminent l'intensité du voxel).
Dans le cas de la segmentation anatomique adulte, cette hypothèse est suffisante pour effectuée la segmentation d'une IRM adulte, mais nécessite l'intégration de nouvelles données de manière à prendre en compte le biais et le bruit.

\subsection{Autres métriques utilisées}
\label{subsec:fcm:dd}

Certains auteurs ont cherché à évaluer l'impact d'une définition alternative de la mesure de similarité entre l'intensité des voxels et les centroïdes des classes.
Deux grandes voies ont été suivies, la première utilisant la distance de Mahalanobis (utile en cas d'utilisation de données multi-spectrales) et la deuxième utilisant des opérateurs noyaux de manière à projeter les données dans un autre espace où la segmentation serait plus aisée.

Concernant l'utilisation des opérateurs noyaux, un état de l'art générale de leur utilisation en clustering est fournit par~\cite{Filippone:PR:2008}.
L'intêret des opérateurs noyaux est leur capacité à séparer des données non-linéaires en projetant les données dans un espace où une séparation linéaire serait possible.
Une exemple de l'utilisation de ces opérateurs est le \emph{Support Vector Machine} (SVM) qui est un algorithme de classification supervisé.

Formellement, les fonctions noyaux sont définis de la façon suivante.
Soit $X=\{\mathbf{x}_1,\ldots,\mathbf{x}_n\}$ un ensemble non vide avec $\mathbf{x}_i \in R^d$.
Une fonction $K : X \times X \rightarrow \mathbb{R}$ est un \emph{noyau défini positif} si et seulement si $K$ est symétrique ($K(\mathbf{x}_i,\mathbf{x}_j) = K(\mathbf{x}_j,\mathbf{x}_i)$) et respecte l'équation suivante :
$$
\sum_{i=1}^n\sum_{j=1}^n c_i c_j K(\mathbf{x}_i,\mathbf{x}_j) \geq 0 \ \forall n \geq 2,
$$
où $c_r \in \mathbb{R}$, $\forall r = 1,\ldots,n.$

Chaque noyau peut être exprimé de la manière suivante :
$$
K(\mathbf{x}_i,\mathbf{x}_j) = \varPhi(\mathbf{x}_i)\cdotp\varPhi(\mathbf{x}_j),
$$
où $\varPhi : X \rightarrow \mathcal{F}$ réalise une transformation de l'espace de départ $X$ vers un espace d'arrivée $\mathcal{F}$ de plus grande dimension.
Cependant, un des aspects les plus intéressants de cette transformation est qu'il est possible de calculer la distance euclidienne dans $\mathcal{F}$ sans pour autant connaître explicitement la transformation $\varPhi$.
En effet, cette distance est donnée par :
$$
\lVert \varPhi(\mathbf{x}_i) - \varPhi(\mathbf{x}_j) \rVert^2 = K(\mathbf{x}_i,\mathbf{x}_i) + K(\mathbf{x}_j,\mathbf{x}_j) - 2K(\mathbf{x}_i,\mathbf{x}_j).
$$

Cette propriété des noyaux permet de définir deux versions de FCM.
La première utilise une méthode de \og kernalisation \fg{} de la métrique~\cite{Zhang:AIM:2004}.
La fonction de coût à minimiser devient alors : 
\begin{equation}
J_{FCM}^{\varPhi} = \sum_{j \in \Omega} \sum_{k=1}^{C} u^{q}_{jk} \lVert \varPhi(\mathbf{y}_{j}) - \varPhi(\mathbf{v}_{k}) \rVert_{2}^{2} \label{eq:fcm:kernel}.
\end{equation}
La fonction d'appartenance est alors calculée par $\frac{1}{u_{jk}} = \sum_{l=1}^{C} \left( \frac{1-K(\mathbf{y}_{j},\mathbf{v}_{k})}{1-K(\mathbf{y}_{j},\mathbf{v}_{l})} \right)$ et les centroïdes par : $\mathbf{v}_k = \frac{\sum_{j \in \Omega} u_{jk}^q K(\mathbf{y}_j,\mathbf{v}_k)\mathbf{y}_j}{\sum_{j \in \Omega} u_{jk}^q K(\mathbf{y}_j,\mathbf{v}_k)}$.
La deuxième possibilité est d'appliquer l'algorithme FCM directement dans l'espace d'arrivée de la transformation $\varPhi$~\cite{Graepel:WFNS:1998}.

Une autre façon de modifier la mesure de similarité et de trouver des frontières entre les classes plus pertinente est d'introduire la distance de Mahalanobis à la place de la distance euclidienne, ce qui revient à définir la mesure de similarité comme~\cite{Gustafson:CDC:1978, He:CMIG:2008} :
$$
D^{2}(\mathbf{y}_{j},\mathbf{v}_{k}) = (\mathbf{y}_{j} - \mathbf{v}_k)^T T_k (\mathbf{y}_{j} - \mathbf{v}_k),
$$
où $T_k$ est une matrice calculée à partir d'une matrice de covariance floue $S_k$ calculée de la façon suivante : 
$$
S_k = \frac{\sum_{j \in \Omega}u_{jk}^{q}(\mathbf{y}_j - \mathbf{v}_k)(\mathbf{y}_j - \mathbf{v}_k)^T}{\sum_{j \in \Omega}u_{jk}^{q}}.
$$
La matrice $T_k$ est déduite de $S_k$ selon : $T_k = \sqrt{\lvert S_k \rvert} S_{k}^{-1}$.
Cette formulation a l'avantage de tenir compte d'une répartition des données autre qu'une répartition sphérique, comme l'hypothèse est faite avec l'utilisation de la norme euclidienne.

Cependant, les formulations décrites cherchent à obtenir une séparation fiable des données par l'utilisation d'un espace plus approprié, mais ne prennent pas en compte la présence de bruit dans l'image.
Deux approches sont intéressantes car elles apportent une réponse à cette problématique par une définition de la similarité.
Nous pouvons citer l'article de~\cite{Shen:TITB:2005}, qui inclue un mécanisme d'attraction du voisinage dans la définition de la similarité en fonction du niveau de gris et de la distance au voxel courant. 
Afin de régler au mieux les paramètres contrôlant les poids respectifs de ces deux termes, une optimisation par un réseau de neurones a également été mise en place.

La deuxième approche est un article de~\cite{Wang:MIA:2009}.
Elle consiste à réaliser une analyse multi-échelle de l'image.
Toute d'abord, un filtre de diffusion est appliqué plusieurs fois à l'image à traité, ce qui a pour effet d'obtenir une image avec un niveau de détails très réduit.
Par la suite, une segmentation de l'image la plus grossière est réalisée par FCM, et ce résultat est utilisé pour réaliser la segmentation à un niveau de détails plus élevé jusqu'à l'image originale.
Cette méthode est intéressante car elle utilise le même principe que la segmentation à l'aide d'un atlas statistique, mais évite les problèmes d'utilisation que peuvent poser un atlas comme le recalage et la construction de l'atlas lui-même.

\subsection{Modélisation du biais en intensité}
\label{subsec:fcm:bias}

La prise en compte du biais en intensité introduit par les imageurs est un problème qui a eu des réponses spécifiques et adaptées à la formulation de l'algorithme FCM.
De manière générale, le signal reçu est modélisé comme le produit du \og vrai \fg{} signal et d'un champ de biais, suposé varier lentement le long du support de l'image.
Cependant, l'application d'une transformée logarithmic à l'espace des intensités  permet de modéliser le signal comme l'addition du vrai signal et du champ de biais, comme dans les travaux de~\cite{Ahmed:TMI:2002}.
L'intensité est donc modélisée par : $\mathbf{y}_j = \mathbf{\dot{y}}_j + b_j$, où $\mathbf{\dot{y}}_j$ représente la \og vraie \fg{} intensité au voxel $j$ et $b_j$ représente le biais au voxel $j$.
L'évaluation du biais représente alors une étape supplémentaire de l'algorithme FCM, après l'évaluation des fonctions d'appartenance et des centroïdes, et est faite de la façon suivante : $b_j = \mathbf{y}_{j} - \frac{\sum_{k=1}^{C}u^q_{jk}\mathbf{v}_k}{\sum_{k=1}^{C}u^q_{jk}}$.

Les travaux de~\cite{Liew:TMI:2003} exploite d'une manière différente l'hypothèse de faible variabilité du biais.
Ce dernier est modélisé comme une pile de surfaces B-Splines.
Ainsi, le biais est évalué par une surface par coupe de l'image avec une régularisation imposant une continuité entre les différentes coupes.
L'évaluation du biais est ainsi réduite au calcul des coefficients contrôlant les différentes surfaces.

Un autre exemple d'estimation du biais est donné par les travaux de~\cite{Li:IPMI:2009}.
Ils introduisent un modèle appelé un clustering des intensité local et cohérent (en anglais : \emph{coherent local intensity clustering} ou \emph{CLIC}) destiné à prendre en compte la similarité des intensité d'un voisinage.
Les voxels de ce voisinage sont pondérés à l'aide d'un noyau gaussien $K(\cdot)$ tronqué de la forme : 
\begin{equation}
K(\mathbf{u}) = 
        \left\{
	\begin{array}{r c}
	        \exp{\frac{-\lvert \mathbf{u} \rvert^2}{2\sigma^2}} & \mbox{ pour } \lvert \mathbf{u} \rvert < \rho \\
	        0 & \mbox{sinon}
	\end{array}
        \right.
\end{equation}
où $\rho$ est le rayon du voisinage pris en compte.
La fonction d'énergie à minimiser devient donc : 
\begin{equation}
J = \sum_{j \in \Omega} \sum_{k = 1}^{C}u_{jk}^q \sum_{l \in \Omega} K(\mathbf{x}_j - \mathbf{x}_l) \lVert \mathbf{y}_{j} - b_{l}\mathbf{v}_{k} \rVert^2.
\end{equation}
L'avantage de cette formulation est que la prise en compte des intensités d'un voisinage autour du voxel courant permet également la correction du bruit de l'image, tout en ajoutant une pondération en fonction de la distance par rapport au voxel courant, partant du principe que seul les voxels les plus proches sont les plus pertinents à prendre en compte.

Tous ces modèles utilisent une modélisation explicite du biais en intensité, ajoutant une étape supplémentaire d'estimation du biais en plus de l'estimation des centroïdes et des fonctions d'appartenance.
De plus, les hypothèses sur la nature multiplicative du biais, ainsi que les faibles variations d'intensité dues à ce phénomène restreignent sa prise en compte.

\subsection{Prise en compte du bruit}
\label{subsec:fcm:noise}

Au début des années 2000, la nécessité d'une prise en compte du bruit produit par les imageurs a conduit à l'introduction de termes de régularisation dans la fonction d'énergie de l'algorithme FCM.
L'idée commune à ces méthodes est l'utilisation de l'environnement autour d'un voxel pour contraindre sa segmentation.
Par exemple, si un voxel est au milieu d'une zone de matière blanche, le processus de segmentation va favoriser sa classification en matière blanche de manière à obtenir une continuité des lables des tissus.

Dans cette optique, deux fonctions d'énergie ont été définies de manière indépendante.
Elles définissent la fonction d'énergie comme la somme d'un terme d'attache aux données, correspondant à l'algorithme FCM classique, et d'un terme de régularisation tenant compte des fonctions d'appartenance des voxels voisins destiné à corriger les fonctions d'appartenance au voxel $j$ en fonction de cet environnement.
La première, appelée FCM robuste (en anglais : \emph{Robust FCM} ou \emph{RFCM})~\cite{Pham:CVIU:2001} ne prend en compte que les fonctions d'appartenance des voxels voisins pour contraindre la segmentation : 
\begin{equation}
J_{RFCM} = \sum_{j \in \Omega} \sum_{k=1}^{C} u^{q}_{jk} \lVert \mathbf{y}_{j} - \mathbf{v}_{k} \rVert_{2}^{2} + \frac{\beta}{2} \sum_{j \in \Omega} \sum_{k=1}^{C} u^{q}_{jk} \sum_{l \in N_j} \sum_{m \in M_k} u^q_{lm}  \label{eq:rfcm},
\end{equation}
où $N_j$ représente un voisinage du voxel courant $j$, $M_k = \{1,\ldots,C\} \backslash \{k\}$ et où $\beta$ contrôle les poids respectifs du terme d'attache aux données et du terme de régularisation.
La deuxième méthodologie, appelée un FCM modifié (en anglais : \emph{Modified FCM} ou \emph{MFCM})~\cite{Ahmed:TMI:2002},  définie la fonction d'énergie de la façon suivante : 
\begin{equation}
J_{RFCM} = \sum_{j \in \Omega} \sum_{k=1}^{C} u^{q}_{jk} \lVert \mathbf{y}_{j} - \mathbf{v}_{k} \rVert_{2}^{2} + \frac{\beta}{\lvert N_j \rvert} \sum_{j \in \Omega} \sum_{k=1}^{C} u^{q}_{jk} \sum_{l \in N_j} \lVert \mathbf{y}_{j} - \mathbf{v}_{k} \rVert^{2}_{2}  \label{eq:mfcm}. 
\end{equation}

La principale différence entre ces deux formulations de la régularisation réside dans l'exploitation du voisinage.
L'algorithme RFCM effectue une régularisation entièrement fondée sur les fonctions d'appartenance, encourageant d'autant plus le lissage de ces fonctions au dur et à mesure des itérations du l'algorithme.
De plus, le lissage de la fonction d'appartenance d'une classe $k$ ne tient compte que des fonctions des autres classes, la logique étant que plus la proportion d'autre classes dans l'environnement est importante, plus la classe courante doit être pénalisée de manière à favoriser les autres classes.
Ceci est illustré par le calcul de la fonction d'appartenance qui s'exprime de la façon suivante : 
\begin{equation}
u_{jk} = \frac{(\lVert \mathbf{y}_{j} - \mathbf{v}_k \rVert_{2}^{2} + \beta \sum_{l \in N_j} \sum_{m \in M_k} u^{q}_{lm})^{-1}}{\sum_{i = 1}^{C}(\lVert \mathbf{y}_{j} - \mathbf{v}_i \rVert_{2}^{2} + \beta \sum_{l \in N_j} \sum_{m \in M_i}u^{q}_{lm})^{-1}}.\label{eq:rfcm:u}
\end{equation}
La forte présence d'autres classes dans le voisinage autour du voxel $j$ entraine une diminution du dénominateur, diminuant d'autant l'appartenance à la classe courante.
A l'inverse, si une forte proportion de la classe courante est présente dans le voisinage, alors seul le terme d'attache aux données est considéré.

L'algorithme MFCM effectue une régularisation par rapport à la similarité entre l'intensité des voxels voisins et le centroïde de la classe courante.
L'analyse de l'expression des fonctions d'appartenance donnée par l'équation \ref{eq:mfcm:u} :
\begin{equation}
u_{jk} = \frac{(\lVert \mathbf{y}_{j} - \mathbf{v}_k \rVert_{2}^{2} + \beta \sum_{l \in N_j} \lVert \mathbf{y}_{l} - \mathbf{v}_{k} \rVert_{2}^{2})^{-1}}{\sum_{i = 1}^{C}(\lVert \mathbf{y}_{j} - \mathbf{v}_i \rVert_{2}^{2} + \beta \sum_{l \in N_j} \lVert \mathbf{y}_{l} - \mathbf{v}_{i} \rVert_{2}^{2})^{-1}} \label{eq:mfcm:u},
\end{equation}
montre que l'ajout de ce terme de régularisation entraine une diminution du dénominateur si l'intensité des voxels voisins est trop dissemblables de la valeur du centroïde.
Le calcul des centroïdes doit prendre en compte le voisinage défini et est donc exprimé de la façon suivante : 
\begin{equation}
\mathbf{v}_k = \frac{\sum_{k=1}^{C} u_{jk}^{q} \left( \mathbf{y}_{j} + \frac{\beta}{\lvert N_j \rvert} \sum_{l \in N_j} \mathbf{y}_l \right)}{(1+\beta) \sum_{k=1}^{C} u_{jk}^{q}}
\end{equation}


L'exploration des différents voisinage étant couteuse en temps de calcul, des améliorations visant l'accélération de l'exécution ont été mise en place.
Les travaux de~\cite{Szilagyi:AICIEEE:2003} parviennent à ce but en définissant une image intermédiaire $\zeta$ définie de la manière suivante : 
\begin{equation}
\mathbf{\zeta}_{j} = \frac{1}{1+\beta} \left( \mathbf{y}_{j} + \frac{\beta}{\lvert N_j \rvert} \sum_{l \in N_j} \mathbf{y}_{l} \right) \label{eq:Szilagyi:Image}.
\end{equation}
De plus, afin de ne pas explorer l'image plusieurs fois au cours des itérations de l'algorithme, un paramètre $\gamma_{p}$ est introduit indiquant le nombre de voxels de l'image à une intensité $p$ donnée (par conséquent, on a bien $\sum_{p = 0}^{p_{max}} \gamma_{p} = N$).
La fonction d'énergie à minimiser s'exprime donc de la façon suivante : 
\begin{equation}
J_{EnFCM} = \sum_{p=0}^{p_{max}} \sum_{k=1}^{C} \gamma_{p} u_{pk}^{q} \lVert \mathbf{\zeta}_{p} - \mathbf{v}_{k} \rVert_{2}^{2} \label{eq:Szilagyi:Cost}.
\end{equation}
Le calcul des fonctions d'appartenance est le même que pour l'algorithme FCM classique, la différence se situant lors du calcul des centroïdes, devant tenir compte du nombre de voxel à une intensité donnée.
Les centroïdes sont donc exprimés selon : 
\begin{equation}
\mathbf{v}_{k} = \frac{\sum_{p = 0}^{p_{max}} \gamma_{p} u_{pk}^{q} \zeta_{p}}{\sum_{p = 0}^{p_{max}} \gamma_{p} u_{pk}^{q}} \label{eq:Szilagyi:centroid}.
\end{equation}
Les avantages de cette méthodologie sont donc un traitement accéléré ainsi qu'une approche beaucoup plus similaire au FCM classique.
De plus, les auteurs montrent que leur algorithme converge plus vite (en moins d'itérations) que la version MFCM.

Toujours en suivant la même idée d'accélérer l'exécution d'un algorithme FCM ayant un terme de régularisation, les travaux de~\cite{Chen:TSMC:2004} introduisent la moyenne ou la médiane du voisinage plutôt que le calcul d'une image complète pour se ramener au cas de l'algorithme FCM classique.
De plus, ils ajoutent l'utilisation d'un noyau gaussien de manière à ajouter une robustesse au bruit et aux \emph{outliers}.
Cet algorithme est appelé le KFCM\_S est la fonction coût à minimiser devient : 
\begin{equation}
J_{KFCM\_S} = \sum_{j \in \Omega} \sum_{k=1}^{C} u^{q}_{jk} (1 - K(\mathbf{y}_j, \mathbf{v}_k)) + \beta \sum_{j \in \Omega} \sum_{k=1}^{C} u^{q}_{jk} (1 - K(\mathbf{\overline{y}}_j, \mathbf{v}_k)),
\end{equation}
où $\mathbf{\overline{y}}_j$ représente la moyenne ou la médiane des intensités dans le voisinage $N_j$.
L'expression des fonctions d'appartenance et des centroïdes est similaire à celle de~\cite{Ahmed:TMI:2002}.
Il existe également une version de cet algorithme n'utilisant pas les opérateurs noyaux, appelé FCM\_S.
% Il suffit de remplacer le terme $\lVert \mathbf{y}_j - \mathbf{v}_k \rVert^{2}_{2}$ par $(1-K(\mathbf{y}_j, \mathbf{v}_k))$ dans le calcul de la fonction d'appartenance.

Cependant, les deux méthodes précédentes, tout comme les méthodes de~\cite{Ahmed:TMI:2002} et \cite{Pham:CVIU:2001}, ont le désavantage de reposer sur un paramètre $\beta$ contrôlant les poids respectifs entre les termes d'attache aux données et le terme de régularisation.
Ce paramètre est choisi la plupart du temps par expérimentation et ce choix est loin d'être intuitif.
De plus, comme dit précédemment, ces algorithmes peuvent devenir très gourmand en temps de calcul à cause de l'exploration des voisinages.
Les travaux de~\cite{Cai:PR:2007} définissent un algorithme FCM généralisé (FGFCM) définissant une image intermédiaire comme décrit dans l'article de~\cite{Szilagyi:AICIEEE:2003} de manière à diminuer les temps de calcul et introduisent une façon d'évaluer localement le poid à attribuer au terme de régularisation en fonction de la position spatiale des voxels et de la similarité des intensités.
Ce paramètre de régularisation locale $S_{jl}$ est défini de la façon suivante : 
\begin{equation}
S_{jl} = \left\{
        \begin{array}{l r}
	S_{s\_jl} \times S_{g\_jl}, & j \neq l, \\
	0, & j = l,
        \end{array}
\right.
\end{equation}
où $S_{s\_jl}$ contrôle la relation spatiale entre les voxels $j$ et $l$ et $S_{g\_jl}$ est fonction de la similarité entre ces deux voxels.
Le paramètre $S_{s\_jl}$ est défini de la façon suivante : 
\begin{equation}
S_{s\_jl} = \exp \left( \frac{-\lVert \mathbf{x}_i - \mathbf{x}_l \rVert}{\lambda_s} \right),
\end{equation}
et le paramètre $S_{g\_jl}$ de la façon suivante : 
\begin{equation}
S_{g\_jl} = \exp \left( \frac{-\lVert \mathbf{y}_j - \mathbf{y}_l \rVert^{2}}{\lambda_g \times \sigma^{2}_{g\_i}} \right),
\end{equation}
où $\sigma_{g\_i}$ est défini comme l'écart moyen entre l'intensité des voxels voisins et le voxel courant.
Ce paramètre est défini de la façon suivante : 
\begin{equation}
\sigma^{2}_{g\_i} = \frac{\sum_{l \in N_j} \lVert \mathbf{y}_j - \mathbf{y}_l \rVert^{2}}{\lvert N_j \rvert}.
\end{equation}
De cette manière, plutôt que d'avoir à fixer un paramètre de régularisation global $\beta$, deux paramètres $\lambda_g$ et $\lambda_s$ dont la définition est plus intuitive.
Le paramètre $\lambda_s$ peut être déduit de la taille du voisinage utilisé, laissant $\lambda_g$ comme seul paramètre global à ajuster.
Avec cette définition du paramètre de régularisation local, il est alors possible de construire une image $\zeta$ selon la formule : 
\begin{equation}
\zeta_{j} = \frac{\sum_{l \in N_j} S_{jl} \mathbf{y}_{j}}{\sum{S_{jl}}}.
\end{equation}
La recherche du minimum de la fonction coût se fait alors selon le même principe que les travaux de~\cite{Szilagyi:AICIEEE:2003}.

Une dernière méthode est à mettre en valeur. 
Constatant que le choix des paramètres de régularisation reste malgré tout difficile (surtout en l'absence d'\emph{a priori} sur le bruit), les travaux de~\cite{Krinidis:TIP:2010} introduisent un nouveau facteur permettant de définir une régularisation sans paramètre contrôlant le poids entre l'attache aux données et la régularisation.
Ce facteur, noté $G_{jk}$, est calculé de la façon suivante : 
\begin{equation}
G_{jk} = \sum_{l \in N_{j},\mbox{ }j \neq l} \frac{1}{\lVert \mathbf{x}_j - \mathbf{x}_l \rVert + 1} (1 - u^{q}_{lk}) \lVert \mathbf{y}_j - \mathbf{v}_k \rVert^{2}_{2}.
\end{equation}
La fonction coût à minimiser devient alors : 
\begin{equation}
J_{FLICM} = \sum_{j \in \Omega} \sum_{k=1}^{C} (u_{jk}^{q} \lVert \mathbf{y}_{j} - \mathbf{v}_{k} \rVert^{2}_{2} + G_{jk}).
\end{equation}
La principale remarque est qu'il n'y a pas de paramètre réglant le poids entre l'attache aux données et la régularisation.
Le poids de la régularisation est déterminé de manière complètement automatique en fonction de la similarité en intensité et de la position spatiale des voxels considérés.
De plus, l'algorithme FLICM travaille directement sur l'image originale et prend en compte la mise à jour des fonctions d'appartenance à chaque itération, évitant ainsi la perte de détails que peut occasionner le calcul d'une image moyenne.


%------------------------------------------------------------------------Maturation cérébrale----------------------------------------------------------------------------------------


\section{Segmentation cérébrale pré et post-natales}

Cette section présente un état de l'art en segmentation des cerveaux en maturation.
Elle concerne les méthodes employées pour effectuer une segmentation des tissus cérébraux dans les cas prénataux et post-nataux.
Ces derniers regroupent plusieurs cas distincts, notamment les prématurés ou les jeunes enfants agés de moins de deux ans.

\subsection{Post-natal}

Une première étude concernant les tissus cérébraux chez les enfants a été effectuée par~\cite{Matsuzawa:CC:2001} et comprends des cas allant de 1 mois à 10 ans.
Il s'agit d'une étude volumétrique cherchant à différencier le LCR, la matière grise et la matière blanche.
Cependant, cette étude ne prend pas en compte un élément capital et qui est la myélinisation de la matière blanche au cours du temps.

Afin de palier à ce défaut, les travaux de~\cite{Prastawa:MIA:2005} ont introduit une séparation de la amtière blanche myélinisée et non myélinisée.
Leur méthode sur trois étapes distincts étant : l'estimation initiale de la distribution en intensité, la correction du biais, puis la correction de la segmentation.
L'estimation initiale de la distribution en intensité est réalisé grâce à un seuillage d'un atlas anatomique préalablement recalé sur le cas à traiter.
Ce seuillage permet de collecter des échantillons de LCR, de matière grise et de matière blanche.
L'estimation de la distribution en intensité du LCR et de la matière grise est faite directement, tandis que la distribution de la matière blanche myélinisée et non myélinisée est obtenue par élagage d'un arbre minimum construit à partir des échantillons des deux types de matière blanche.
La correction du biais est obtenue selon la méthode de~\cite{VanLeemput1:TMI:1999}.
La dernière étape est réalisé par l'utilisation d'une méthode d'estimation de la distribution en intensité non-paramétrique à cause notamment des forts recouvrements dues à une modélisation gaussienne.
Une nouvelle fois, des échantillons suposés fiables sont tirés de l'image et permettent une estimation de la distribution en intensité par l'utilisation de fonctions noyaux.

\cite{Xue:NeuroImage:2007} : Segmentation des tissus en excluant les noyaux gris + Champs de Markov adaptatifs localement + atlas. Extraction du cerveau par level-set.

\cite{Weisenfeld:NeuroImage:2009} : Segmentation des nouveaux nés par une phase d'apprentissage automatique conduite par une sélection de prototypes et une estimation des distributions d'intensités non-paramétrique. Ils disposent pour ce faire d'une bibliothèque de cas typiques fournissant ces prototypes pour chaque tissus.

\cite{Merisaari:JNM:2009} : Segmentation en deux étapes : watershed et classification des régions obtenus + utilisation de cette première classification comme \emph{a priori} pour une classification voxel à voxel.

\cite{Shi:NeuroImage:2010} : Utilisation d'une segmentation à un temps t comme atlas pour une segmentation d'un même patient à un temps t-1.

\cite{Shi:HBM:2011} : Utilisation d'un atlas pondéré par une carte de confiance corticale issue d'un filtre hessien dont la zone autour des ventricules a été exclue à l'aide d'un template.

Idée principale : une atlas ou une classification supervisée est nécessaire.

Exception : (pas encore paru, mais je le cite ici pour éviter de l'oublier) \cite{Gui:ISBI:2011}, segmentation par une série d'opérations morphologiques, croissance de région et \emph{a priori} anatomiques.

\subsection{Prénatal}
\label{prenatal}

\cite{Claude:TBE:2004} : Segmentation semi-automatique.

\cite{Ferrario:ESPC:2008} : Segmentation du volume intracrânien avec une étape de classification par mixture de gaussienne et une étape de reclassification à l'aide de champs de Markov.

\cite{Anquez:ISBI:2009} : Segmentation du volume intracrânien par détection des yeux, \emph{a priori} anatomiques et opérateurs de morphologie mathématique.

\cite{BachCuedra:MICCAI:2009} : Segmentation avec une étape de classification par mixture de gaussienne et une étape de régularisation déconnectée des données avec des \emph{a priori} anatomiques.

\cite{Habas:SPIE:2009} : Segmentation à l'aide d'un atlas incluant un modèle de structures laminaires à partir des ventricules.

\cite{Gholipour:IJCARS:2010} : Étude sur le volume intracrânien à l'aide d'une segmentation combinant level-sets, composantes connexes et opérateurs de morpho-maths.

\cite{Habas:NeuroImage:2010} : Segmentation à l'aide d'un atlas spatio-temporel.

Pour la reconstruction de volumes 3D : \cite{Kim:TMI:2010,Rousseau:AR:2006}.

%------------------------------------------------------------------------Bilan----------------------------------------------------------------------------------------

\section{Bilan}
Positionnement des travaux.
